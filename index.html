<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Theresa Eimer</title> <meta name="author" content="Theresa Eimer"> <meta name="description" content="Hi, I'm Theresa, a RL researcher on the hunt for general agents and DACs. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%8D&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://theeimer.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%74.%65%69%6D%65%72@%61%69.%75%6E%69-%68%61%6E%6E%6F%76%65%72.%64%65" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0000-0001-5561-5908" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=nKbDyf0AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/TheEimer" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://twitter.com/The_Eimer" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">Hi there!<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link text-lowercase" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link text-lowercase" href="/cv/">CV</a> </li> <li class="nav-item "> <a class="nav-link text-lowercase" href="/teaching/">Teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Theresa</span> Eimer </h1> <p class="desc">Researcher at the <a href="https://www.ai.uni-hannover.de/de/institut/team/eimer/" rel="external nofollow noopener" target="_blank">Insitutite of AI Hannover</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/pic-1400.webp"></source> <img src="/assets/img/pic.jpg" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>I am a researcher at the Leibniz University of Hannover leading the Reinforcement Learning team in Prof. Lindauer’s AutoML group. I focus on making RL agents more general by dynamically adapting their behavior. I’m interested in all things AutoRL, especially dynamic algorithm configuration for RL and curriculum learning, as well as generalization in RL.</p> <p>I completed my PhD in 2024 und the supervision of Prof. Marius Lindauer. I have interned at MetaAI in London in 2022/23. If you want to chat (about research or otherwise), feel free to book a slot in my <a href="https://calendar.app.google/tMdop6qyU59B1XF5A" rel="external nofollow noopener" target="_blank">calendar</a>!</p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Nov 18, 2024</th> <td> After almost five years, I successfully defended my PhD thesis and received a grade of summa cum laude for it! Thank you to everyone who helped me along the way. </td> </tr> <tr> <th scope="row">Oct 2, 2024</th> <td> I’m very pleased to be selected as a fellow of the Zeit Zia program for 2024/25. Looking forward to meeting exciting people and learning a lot in the coming year! </td> </tr> <tr> <th scope="row">Apr 30, 2024</th> <td> Excited to announce the first edition of the <a href="https://autorlworkshop.github.io/" rel="external nofollow noopener" target="_blank">AutoRL</a> workshop at this year’s ICML! </td> </tr> <tr> <th scope="row">Sep 25, 2023</th> <td> I’m excited to have been chosen as one of the 19 young researchers invited to the Future of AI Summit in Aachen this week! I’ll be talking about my vision for AutoRL as a paradigm to make RL more robust, efficient and general. </td> </tr> <tr> <th scope="row">Sep 21, 2023</th> <td> I’ve had a great time in Brussels at <a href="https://ewrl.wordpress.com/ewrl16-2023/" rel="external nofollow noopener" target="_blank">EWRL</a>. If you’re interested in my favorite papers, take a look at this <a href="https://twitter.com/The_Eimer/status/1704759665484075302" rel="external nofollow noopener" target="_blank">Twitter thread</a>. </td> </tr> </table> </div> </div> <h2><a href="/blog/" style="color: inherit;">latest posts</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Nov 3, 2024</th> <td> <a class="news-title" href="/blog/2024/ewrl/">EWRL17 Recap</a> </td> </tr> <tr> <th scope="row">Sep 25, 2024</th> <td> <a class="news-title" href="https://www.automl.org/introducing-hypersweeper-bridging-the-hpo-gap-between-automl-research-and-ml-practitioners/" target="_blank" rel="external nofollow noopener">Introducing Hypersweeper: Bridging the HPO Gap Between AutoML Research and ML Practitioners</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </td> </tr> <tr> <th scope="row">Jan 11, 2024</th> <td> <a class="news-title" href="http://autorl.org/blog/retrospective/" target="_blank" rel="external nofollow noopener">2023 in AutoRL</a> <svg width="2rem" height="2rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="parker-holder-jair22" class="col-sm-8"> <div class="title">Automated Reinforcement Learning (AutoRL): A Survey and Open Problems</div> <div class="author"> Jack Parker-Holder, <a href="https://ml.informatik.uni-freiburg.de/profile/rajan/" rel="external nofollow noopener" target="_blank">Raghu Rajan</a>, Xingyou Song, <a href="https://andrebiedenkapp.github.io/" rel="external nofollow noopener" target="_blank">André Biedenkapp</a>, Yingjie Miao, <em>Theresa Eimer</em>, Baohe Zhang, Vu Nguyen, Roberto Calandra, Aleksandra Faust, <a href="https://ml.informatik.uni-freiburg.de/profile/hutter" rel="external nofollow noopener" target="_blank">Frank Hutter</a>, and <a href="https://www.ai.uni-hannover.de/en/institut/team/lindauer" rel="external nofollow noopener" target="_blank">Marius Lindauer</a> </div> <div class="periodical"> <em>Journal of Artificial Intelligence Research (JAIR)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/paper/jair_22_autorl_survey.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.automl.org/automated-reinforcement-learning/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The combination of Reinforcement Learning (RL) with deep learning has led to a series of impressive feats, with many believing (deep) RL provides a path towards generally capable agents. However, the success of RL agents is often highly sensitive to design choices in the training process, which may require tedious and error-prone manual tuning. This makes it challenging to use RL for new problems, while also limits its full potential. In many other areas of machine learning, AutoML has shown it is possible to automate such design choices and has also yielded promising initial results when applied to RL. However, Automated Reinforcement Learning (AutoRL) involves not only standard applications of AutoML but also includes additional challenges unique to RL, that naturally produce a different set of methods. As such, AutoRL has been emerging as an important area of research in RL, providing promise in a variety of applications from RNA design to playing games such as Go. Given the diversity of methods and environments considered in RL, much of the research has been conducted in distinct subfields, ranging from meta-learning to evolution. In this survey we seek to unify the field of AutoRL, we provide a common taxonomy, discuss each area in detail and pose open problems which would be of interest to researchers going forward.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">parker-holder-jair22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Parker{-}Holder, Jack and Rajan, Raghu and Song, Xingyou and Biedenkapp, André and Miao, Yingjie and Eimer, Theresa and Zhang, Baohe and Nguyen, Vu and Calandra, Roberto and Faust, Aleksandra and Hutter, Frank and Lindauer, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated Reinforcement Learning (AutoRL): {A} Survey and Open Problems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Artificial Intelligence Research (JAIR)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{517-568}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{74}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="benjamins-tmlr23" class="col-sm-8"> <div class="title">Contextualize Me - The Case for Context in Reinforcement Learning</div> <div class="author"> <a href="https://www.ai.uni-hannover.de/en/institut/team/benjamins" rel="external nofollow noopener" target="_blank">Carolin Benjamins</a>, <em>Theresa Eimer</em>, <a href="http://www.tnt.uni-hannover.de/en/staff/schubert/" rel="external nofollow noopener" target="_blank">Frederik Schubert</a>, Sebastian Döhler, <a href="https://www.ai.uni-hannover.de/en/institut/team/mohan" rel="external nofollow noopener" target="_blank">Aditya Mohan</a>, <a href="https://andrebiedenkapp.github.io/" rel="external nofollow noopener" target="_blank">André Biedenkapp</a>, <a href="http://www.tnt.uni-hannover.de/en/staff/rosenhahn/" rel="external nofollow noopener" target="_blank">Bodo Rosenhahn</a>, <a href="https://ml.informatik.uni-freiburg.de/profile/hutter" rel="external nofollow noopener" target="_blank">Frank Hutter</a>, and <a href="https://www.ai.uni-hannover.de/en/institut/team/lindauer" rel="external nofollow noopener" target="_blank">Marius Lindauer</a> </div> <div class="periodical"> <em>Transactions on Machine Learning Research</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/paper/tmlr_23_contextualize_me.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/automl/CARL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://www.automl.org/carl-a-benchmark-to-study-generalization-in-reinforcement-learning/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>While Reinforcement Learning (RL) has made great strides towards solving increasingly complicated problems, many algorithms are still brittle to even slight environmental changes. Contextual Reinforcement Learning (cRL) provides a framework to model such changes in a principled manner, thereby enabling flexible, precise and interpretable task specification and generation. Our goal is to show how the framework of cRL contributes to improving zero-shot generalization in RL through meaningful benchmarks and structured reasoning about generalization tasks. We confirm the insight that optimal behavior in cRL requires context information, as in other related areas of partial observability. To empirically validate this in the cRL framework, we provide various context-extended versions of common RL environments. They are part of the first benchmark library, CARL, designed for generalization based on cRL extensions of popular benchmarks, which we propose as a testbed to further study general agents. We show that in the contextual setting, even simple RL environments become challenging - and that naive solutions are not enough to generalize across complex context spaces.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">benjamins-tmlr23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Benjamins, Carolin and Eimer, Theresa and Schubert, Frederik and Döhler, Sebastian and Mohan, Aditya and Biedenkapp, André and Rosenhahn, Bodo and Hutter, Frank and Lindauer, Marius}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Contextualize Me - The Case for Context in Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Transactions on Machine Learning Research}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="beckdierkes-ewrl24" class="col-sm-8"> <div class="title">ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization in Reinforcement Learning</div> <div class="author"> Jannis Becktepe, Julian Dierkes, <a href="https://www.ai.uni-hannover.de/en/institut/team/benjamins" rel="external nofollow noopener" target="_blank">Carolin Benjamins</a>, <a href="https://www.ai.uni-hannover.de/en/institut/team/mohan" rel="external nofollow noopener" target="_blank">Aditya Mohan</a>, David Salinas, <a href="https://ml.informatik.uni-freiburg.de/profile/rajan/" rel="external nofollow noopener" target="_blank">Raghu Rajan</a>, <a href="https://ml.informatik.uni-freiburg.de/profile/hutter" rel="external nofollow noopener" target="_blank">Frank Hutter</a>, Holger H. Hoos, <a href="https://www.ai.uni-hannover.de/en/institut/team/lindauer" rel="external nofollow noopener" target="_blank">Marius Lindauer</a>, and <em>Theresa Eimer</em> </div> <div class="periodical"> <em>In 17th European Workshop on Reinforcement Learning (EWRL)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/automl/arlbench" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://arxiv.org/abs/2409.18827" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Hyperparameters are a critical factor in reliably training well-performing reinforcement learning (RL) agents. Unfortunately, developing and evaluating automated approaches for tuning such hyperparameters is both costly and time-consuming. As a result, such approaches are often only evaluated on a single domain or algorithm, making comparisons difficult and limiting insights into their generalizability. We propose ARLBench, a benchmark for hyperparameter optimization (HPO) in RL that allows comparisons of diverse HPO approaches while being highly efficient in evaluation. To enable research into HPO in RL, even in settings with low compute resources, we select a representative subset of HPO tasks spanning a variety of algorithm and environment combinations. This selection allows for generating a performance profile of an automated RL (AutoRL) method using only a fraction of the compute previously necessary, enabling a broader range of researchers to work on HPO in RL. With the extensive and large-scale dataset on hyperparameter landscapes that our selection is based on, ARLBench is an efficient, flexible, and future-oriented foundation for research on AutoRL. Both the benchmark and the dataset are available at https://github.com/automl/arlbench.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">beckdierkes-ewrl24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Becktepe, Jannis and Dierkes, Julian and Benjamins, Carolin and Mohan, Aditya and Salinas, David and Rajan, Raghu and Hutter, Frank and Hoos, Holger H. and Lindauer, Marius and Eimer, Theresa}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization
                    in Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{17th European Workshop on Reinforcement Learning (EWRL)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%74.%65%69%6D%65%72@%61%69.%75%6E%69-%68%61%6E%6E%6F%76%65%72.%64%65" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0000-0001-5561-5908" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=nKbDyf0AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/TheEimer" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://twitter.com/The_Eimer" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> Feel free to e-mail me or say hi on Twitter! </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Theresa Eimer. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. <a href="https://theeimer.github.io/impressum/">Impressum</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>